---
title: "We are Electric"
authors:
  - name: "Dog Cat"
    link: "FIRST AUTHOR PERSONAL LINK"
  - name: "Pistacchio Cookies"
    link: "SECOND AUTHOR PERSONAL LINK"
  - name: "Third Author"
    link: "THIRD AUTHOR PERSONAL LINK"
institution: "MBZUAI"
conference: "Soon to be submitted"
paperLink: "https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf"
githubLink: "https://github.com/YOUR REPO HERE"
arxivLink: "https://arxiv.org/abs/<ARXIV PAPER ID>"
teaserVideo: "static/videos/banner_video.mp4"
teaserDescription: "Aliquam vitae elit ullamcorper tellus egestas pellentesque."

youtubeEmbed: "https://www.youtube.com/embed/JkaxUblCGz0"

sectionsOrder:
  - bibtex:
      bibtex: |
        @article{example2024,
          title={Example Title},
          author={Author, A.},
          journal={Journal Name},
          year={2024}
        }
---

{{% abstract %}}
Visual Question Answering (VQA) is an important task in multimodal AI, which requires models to understand and reason about the knowledge in both visual and textual information of the data. However, most of the current VQA datasets and models a reprimarily focused on English and a few major world languages. Although some studies put some efforts to extend VQA datasets to multilingual, they still lack diversity in low-resource languages. More importantly, the diversity of visual information (e.g. the image should reflect local language culture) is ignored to some extent - in other words previous work on building multilingual VQA data mainly focuses on extending the language side to multilingual. To address this limitation, we propose a new multilingual multimodal VQA benchmark that emphasizes culturally-diverse data across a wide range of languages. By engaging native speakers and cultural experts in the data collection process and sourcing images from diverse geographic regions, we aim to create a more inclusive and representative dataset. With this benchmark serving as a probing evaluation suite for assessing the cultural bias of current multimodal models will promote the development of culturally-aware and linguistically comprehensive VQA models, encouraging fairness and reducing bias in AI systems.
{{% /abstract %}}

{{% text-section "./content/introduction.md" %}}
{{% text-section "./content/method.md" %}}
{{% text-section "./content/experiment-result.md" %}}
{{% text-section "./content/leaderboard.md" %}}


